(trojen) abhinav.pm@node01:~/ABHI/SAL/v4$ python3 train_s2p.py
======================================================================
            Speech-to-PHONEME Training (OPTIMIZED)
          (On-the-fly audio processing - much faster!)
======================================================================

üìã Configuration:
   Dataset cache: /scratch/ABHI/huggingface_cache2
   TSV directory: /home/abhinav.pm/ABHI/SAL/v4/phonemized
   Output dir: ./s2p_model_polish_phoneme_v1
   Test mode: False

[1/7] Loading phonemized TSV files...
   ‚úì Train: 24173 rows
   ‚úì Test: 9856 rows
   ‚úì Valid: 9856 rows
   ‚úì Train after filtering: 24173 rows (removed 0)
   ‚úì Test after filtering: 9856 rows (removed 0)
   ‚úì Valid after filtering: 9856 rows (removed 0)

   ‚úì Phoneme dictionaries created:
      Train: 24173 entries
      Test: 9856 entries
      Valid: 9856 entries

   Example phonemes from train:
   1. common_voice_pl_20603611.mp3: and í…õju k É…®kn…îw…õm …îpasuj…înts ramj…õ…≤ ≤…õm …°watki …îbw…® t É…în
   2. common_voice_pl_20605050.mp3: …≤ ≤…õ tak t…î watf…î
   3. common_voice_pl_20662945.mp3: na pr…î…°u j…õ Ét É…õ p É…®stan…îw p…îpat Éaw i p…î É…õd

[2/7] Loading HuggingFace datasets from cache...
Using the latest cached version of the dataset since fsicoli/common_voice_22_0 couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'pl' at /scratch/ABHI/huggingface_cache2/fsicoli___common_voice_22_0/pl/22.0.0/9d3b21d6c5398bd4e5196375ed1407a1b40d13bf44cb94a54675e9cd45ee4cca (last modified on Wed Nov  5 13:14:36 2025).
Using the latest cached version of the dataset since fsicoli/common_voice_22_0 couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'pl' at /scratch/ABHI/huggingface_cache2/fsicoli___common_voice_22_0/pl/22.0.0/9d3b21d6c5398bd4e5196375ed1407a1b40d13bf44cb94a54675e9cd45ee4cca (last modified on Wed Nov  5 13:14:36 2025).
Using the latest cached version of the dataset since fsicoli/common_voice_22_0 couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'pl' at /scratch/ABHI/huggingface_cache2/fsicoli___common_voice_22_0/pl/22.0.0/9d3b21d6c5398bd4e5196375ed1407a1b40d13bf44cb94a54675e9cd45ee4cca (last modified on Wed Nov  5 13:14:36 2025).
   ‚úì Train dataset: 24173 samples
   ‚úì Test dataset: 9856 samples
   ‚úì Valid dataset: 9856 samples

[3/7] Creating dataset indices (fast - no audio loading)...
   Indexing train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 24173/24173 [00:01<00:00, 19785.19it/s]
   Indexing test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9856/9856 [00:00<00:00, 20428.48it/s]
   Indexing valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9856/9856 [00:00<00:00, 20347.78it/s]

   ‚úì Matched indices:
      Train: 24173 samples
      Test: 9856 samples
      Valid: 9856 samples

[4/7] Creating PHONEME vocabulary from training data...
   Collecting phonemes: 100%|‚ñà| 24173/24173 [00:01<00:00, 19819.70it/s
   ‚úì Vocabulary size: 39
   ‚úì Saved to: ./s2p_model_polish_phoneme_v1/vocab.json

   Sample phonemes in vocabulary:
     a b d f h i j k l m n p r s t u v w x

[5/7] Creating processor...
   ‚úì Processor created and saved

[6/7] Creating on-the-fly datasets...
   ‚úì On-the-fly datasets created
      Train: 24173 samples
      Valid: 9856 samples

[7/7] Setting up model and training...
   Loading model: facebook/wav2vec2-large-xlsr-53
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
   ‚úì Model loaded (feature encoder frozen)

   Training configuration:
      - Train samples: 24,173
      - Valid samples: 9,856
      - Epochs: 10
      - Batch size: 16 x 2 = 32
      - Learning rate: 0.0001
      - Device: GPU (fp16)
      - Workers: 4 (parallel audio loading)
      - Vocabulary size: 39

======================================================================
Starting training...
Audio will be loaded and processed ON-THE-FLY during training!
======================================================================

{'loss': 14.197, 'grad_norm': 6.878188133239746, 'learning_rate': 9.4e-06, 'epoch': 0.07}
{'loss': 12.5759, 'grad_norm': 20.107881546020508, 'learning_rate': 1.94e-05, 'epoch': 0.13}
{'loss': 6.619, 'grad_norm': 6.728801250457764, 'learning_rate': 2.9199999999999998e-05, 'epoch': 0.2}
{'loss': 3.8314, 'grad_norm': 1.079759120941162, 'learning_rate': 3.9200000000000004e-05, 'epoch': 0.26}
{'loss': 3.3819, 'grad_norm': 0.8186274170875549, 'learning_rate': 4.92e-05, 'epoch': 0.33}
{'loss': 3.3269, 'grad_norm': 1.8319743871688843, 'learning_rate': 5.92e-05, 'epoch': 0.4}
{'loss': 3.2827, 'grad_norm': 4.420611381530762, 'learning_rate': 6.92e-05, 'epoch': 0.46}
{'loss': 3.2655, 'grad_norm': 0.6918901205062866, 'learning_rate': 7.920000000000001e-05, 'epoch': 0.53}
{'loss': 3.2603, 'grad_norm': 0.9779279828071594, 'learning_rate': 8.92e-05, 'epoch': 0.6}
{'loss': 3.2486, 'grad_norm': 0.344887375831604, 'learning_rate': 9.92e-05, 'epoch': 0.66}
{'eval_loss': 3.2349321842193604, 'eval_runtime': 47.8236, 'eval_samples_per_second': 206.091, 'eval_steps_per_second': 25.761, 'epoch': 0.66}
{'loss': 3.2336, 'grad_norm': 0.4006226658821106, 'learning_rate': 9.934844192634561e-05, 'epoch': 0.73}
{'loss': 3.0576, 'grad_norm': 4.782066822052002, 'learning_rate': 9.864022662889519e-05, 'epoch': 0.79}
{'loss': 2.6108, 'grad_norm': 0.8929550647735596, 'learning_rate': 9.793201133144476e-05, 'epoch': 0.86}
{'loss': 1.5782, 'grad_norm': 2.249586343765259, 'learning_rate': 9.722379603399434e-05, 'epoch': 0.93}
{'loss': 1.0052, 'grad_norm': 0.929604172706604, 'learning_rate': 9.65155807365439e-05, 'epoch': 0.99}
{'loss': 0.7951, 'grad_norm': 1.039598822593689, 'learning_rate': 9.580736543909348e-05, 'epoch': 1.06}
{'loss': 0.6933, 'grad_norm': 6.57623815536499, 'learning_rate': 9.511331444759208e-05, 'epoch': 1.12}
{'loss': 0.5986, 'grad_norm': 0.9872416853904724, 'learning_rate': 9.440509915014166e-05, 'epoch': 1.19}
{'loss': 0.5723, 'grad_norm': 1.4152580499649048, 'learning_rate': 9.369688385269122e-05, 'epoch': 1.26}
{'loss': 0.4934, 'grad_norm': 0.9211050868034363, 'learning_rate': 9.29886685552408e-05, 'epoch': 1.32}
{'eval_loss': 0.26002541184425354, 'eval_runtime': 47.5106, 'eval_samples_per_second': 207.449, 'eval_steps_per_second': 25.931, 'epoch': 1.32}
{'loss': 0.4876, 'grad_norm': 1.3773338794708252, 'learning_rate': 9.228045325779038e-05, 'epoch': 1.39}
{'loss': 0.4724, 'grad_norm': 1.1608928442001343, 'learning_rate': 9.157223796033995e-05, 'epoch': 1.46}
{'loss': 0.4314, 'grad_norm': 0.8190276026725769, 'learning_rate': 9.086402266288953e-05, 'epoch': 1.52}
{'loss': 0.4316, 'grad_norm': 1.1244547367095947, 'learning_rate': 9.015580736543909e-05, 'epoch': 1.59}
{'loss': 0.4008, 'grad_norm': 0.8237683176994324, 'learning_rate': 8.944759206798867e-05, 'epoch': 1.65}
{'loss': 0.3737, 'grad_norm': 0.766899585723877, 'learning_rate': 8.873937677053825e-05, 'epoch': 1.72}
{'loss': 0.3789, 'grad_norm': 0.9378941655158997, 'learning_rate': 8.803116147308781e-05, 'epoch': 1.79}
{'loss': 0.3708, 'grad_norm': 0.9238236546516418, 'learning_rate': 8.73229461756374e-05, 'epoch': 1.85}
{'loss': 0.3646, 'grad_norm': 0.8873915076255798, 'learning_rate': 8.661473087818697e-05, 'epoch': 1.92}
{'loss': 0.3465, 'grad_norm': 1.0800580978393555, 'learning_rate': 8.590651558073655e-05, 'epoch': 1.98}
{'eval_loss': 0.18154558539390564, 'eval_runtime': 47.2954, 'eval_samples_per_second': 208.393, 'eval_steps_per_second': 26.049, 'epoch': 1.98}
{'loss': 0.346, 'grad_norm': 1.6607722043991089, 'learning_rate': 8.519830028328613e-05, 'epoch': 2.05}
{'loss': 0.3608, 'grad_norm': 1.017715334892273, 'learning_rate': 8.44900849858357e-05, 'epoch': 2.12}
{'loss': 0.3287, 'grad_norm': 0.7389398813247681, 'learning_rate': 8.378186968838528e-05, 'epoch': 2.18}
{'loss': 0.2941, 'grad_norm': 0.9779411554336548, 'learning_rate': 8.307365439093485e-05, 'epoch': 2.25}
{'loss': 0.2956, 'grad_norm': 1.0362138748168945, 'learning_rate': 8.236543909348442e-05, 'epoch': 2.32}
{'loss': 0.2844, 'grad_norm': 0.7367892861366272, 'learning_rate': 8.1657223796034e-05, 'epoch': 2.38}
{'loss': 0.3063, 'grad_norm': 1.0667505264282227, 'learning_rate': 8.094900849858358e-05, 'epoch': 2.45}
{'loss': 0.2993, 'grad_norm': 0.6622637510299683, 'learning_rate': 8.024079320113314e-05, 'epoch': 2.51}
{'loss': 0.2929, 'grad_norm': 0.49846330285072327, 'learning_rate': 7.953257790368272e-05, 'epoch': 2.58}
{'loss': 0.3021, 'grad_norm': 0.9921643137931824, 'learning_rate': 7.882436260623229e-05, 'epoch': 2.65}
{'eval_loss': 0.16170600056648254, 'eval_runtime': 47.5961, 'eval_samples_per_second': 207.076, 'eval_steps_per_second': 25.884, 'epoch': 2.65}
{'loss': 0.3013, 'grad_norm': 0.8162758946418762, 'learning_rate': 7.811614730878187e-05, 'epoch': 2.71}
{'loss': 0.2755, 'grad_norm': 0.643886387348175, 'learning_rate': 7.740793201133145e-05, 'epoch': 2.78}
{'loss': 0.2794, 'grad_norm': 0.7049708962440491, 'learning_rate': 7.669971671388103e-05, 'epoch': 2.84}
{'loss': 0.2802, 'grad_norm': 0.7414941191673279, 'learning_rate': 7.59915014164306e-05, 'epoch': 2.91}
{'loss': 0.2814, 'grad_norm': 0.6852738261222839, 'learning_rate': 7.528328611898018e-05, 'epoch': 2.98}
{'loss': 0.2768, 'grad_norm': 0.8074219822883606, 'learning_rate': 7.457507082152975e-05, 'epoch': 3.04}
{'loss': 0.2635, 'grad_norm': 1.0022711753845215, 'learning_rate': 7.386685552407933e-05, 'epoch': 3.11}
{'loss': 0.2564, 'grad_norm': 1.0806777477264404, 'learning_rate': 7.31586402266289e-05, 'epoch': 3.17}
{'loss': 0.263, 'grad_norm': 0.6469447612762451, 'learning_rate': 7.245042492917847e-05, 'epoch': 3.24}
{'loss': 0.2597, 'grad_norm': 0.7529681324958801, 'learning_rate': 7.174220963172805e-05, 'epoch': 3.31}
{'eval_loss': 0.15114304423332214, 'eval_runtime': 47.4954, 'eval_samples_per_second': 207.515, 'eval_steps_per_second': 25.939, 'epoch': 3.31}
{'loss': 0.2285, 'grad_norm': 0.7433992624282837, 'learning_rate': 7.103399433427762e-05, 'epoch': 3.37}
{'loss': 0.2636, 'grad_norm': 0.7580315470695496, 'learning_rate': 7.03257790368272e-05, 'epoch': 3.44}
{'loss': 0.2395, 'grad_norm': 0.5205108523368835, 'learning_rate': 6.961756373937678e-05, 'epoch': 3.51}
{'loss': 0.2264, 'grad_norm': 0.6690905094146729, 'learning_rate': 6.890934844192634e-05, 'epoch': 3.57}
{'loss': 0.2393, 'grad_norm': 1.500097632408142, 'learning_rate': 6.820113314447592e-05, 'epoch': 3.64}
{'loss': 0.2533, 'grad_norm': 0.9431124925613403, 'learning_rate': 6.74929178470255e-05, 'epoch': 3.7}
{'loss': 0.2458, 'grad_norm': 0.6429097652435303, 'learning_rate': 6.678470254957508e-05, 'epoch': 3.77}
{'loss': 0.2213, 'grad_norm': 0.511303186416626, 'learning_rate': 6.607648725212466e-05, 'epoch': 3.84}
{'loss': 0.2232, 'grad_norm': 0.8378722667694092, 'learning_rate': 6.536827195467422e-05, 'epoch': 3.9}
{'loss': 0.2427, 'grad_norm': 0.9866312146186829, 'learning_rate': 6.46600566572238e-05, 'epoch': 3.97}
{'eval_loss': 0.13875652849674225, 'eval_runtime': 47.3604, 'eval_samples_per_second': 208.106, 'eval_steps_per_second': 26.013, 'epoch': 3.97}
{'loss': 0.2302, 'grad_norm': 0.7494193315505981, 'learning_rate': 6.395184135977338e-05, 'epoch': 4.03}
{'loss': 0.2381, 'grad_norm': 0.6827794909477234, 'learning_rate': 6.324362606232295e-05, 'epoch': 4.1}
{'loss': 0.2191, 'grad_norm': 0.6058768033981323, 'learning_rate': 6.253541076487253e-05, 'epoch': 4.17}
{'loss': 0.2204, 'grad_norm': 0.9487051367759705, 'learning_rate': 6.182719546742209e-05, 'epoch': 4.23}
{'loss': 0.2255, 'grad_norm': 1.2362043857574463, 'learning_rate': 6.111898016997167e-05, 'epoch': 4.3}
{'loss': 0.2168, 'grad_norm': 0.7559428215026855, 'learning_rate': 6.0410764872521255e-05, 'epoch': 4.37}
{'loss': 0.2138, 'grad_norm': 1.4210819005966187, 'learning_rate': 5.970254957507082e-05, 'epoch': 4.43}
{'loss': 0.2147, 'grad_norm': 0.9596824049949646, 'learning_rate': 5.89943342776204e-05, 'epoch': 4.5}
{'loss': 0.2132, 'grad_norm': 0.7669227719306946, 'learning_rate': 5.828611898016998e-05, 'epoch': 4.56}
{'loss': 0.2115, 'grad_norm': 1.2678977251052856, 'learning_rate': 5.7577903682719545e-05, 'epoch': 4.63}
{'eval_loss': 0.13502679765224457, 'eval_runtime': 47.4613, 'eval_samples_per_second': 207.664, 'eval_steps_per_second': 25.958, 'epoch': 4.63}
{'loss': 0.2085, 'grad_norm': 0.6684141159057617, 'learning_rate': 5.6869688385269124e-05, 'epoch': 4.7}
{'loss': 0.22, 'grad_norm': 1.058189034461975, 'learning_rate': 5.6161473087818696e-05, 'epoch': 4.76}
{'loss': 0.2025, 'grad_norm': 0.5936175584793091, 'learning_rate': 5.5453257790368275e-05, 'epoch': 4.83}
{'loss': 0.2138, 'grad_norm': 0.6388072371482849, 'learning_rate': 5.4745042492917854e-05, 'epoch': 4.89}
{'loss': 0.2162, 'grad_norm': 0.7259389162063599, 'learning_rate': 5.403682719546742e-05, 'epoch': 4.96}
{'loss': 0.1948, 'grad_norm': 0.6031578779220581, 'learning_rate': 5.3328611898017e-05, 'epoch': 5.03}
{'loss': 0.2017, 'grad_norm': 0.6711673736572266, 'learning_rate': 5.262039660056658e-05, 'epoch': 5.09}
{'loss': 0.1928, 'grad_norm': 0.8221429586410522, 'learning_rate': 5.191218130311615e-05, 'epoch': 5.16}
{'loss': 0.2105, 'grad_norm': 1.081976294517517, 'learning_rate': 5.120396600566573e-05, 'epoch': 5.23}
{'loss': 0.1762, 'grad_norm': 0.8594508171081543, 'learning_rate': 5.0495750708215294e-05, 'epoch': 5.29}
{'eval_loss': 0.1314716637134552, 'eval_runtime': 47.4754, 'eval_samples_per_second': 207.602, 'eval_steps_per_second': 25.95, 'epoch': 5.29}
{'loss': 0.19, 'grad_norm': 0.8476588129997253, 'learning_rate': 4.9787535410764873e-05, 'epoch': 5.36}
{'loss': 0.2065, 'grad_norm': 0.7441957592964172, 'learning_rate': 4.9079320113314446e-05, 'epoch': 5.42}
{'loss': 0.1879, 'grad_norm': 0.7312439680099487, 'learning_rate': 4.8371104815864025e-05, 'epoch': 5.49}
{'loss': 0.2057, 'grad_norm': 0.7280876636505127, 'learning_rate': 4.7662889518413604e-05, 'epoch': 5.56}
{'loss': 0.1963, 'grad_norm': 0.7168412208557129, 'learning_rate': 4.6954674220963176e-05, 'epoch': 5.62}
{'loss': 0.2021, 'grad_norm': 0.6324981451034546, 'learning_rate': 4.624645892351275e-05, 'epoch': 5.69}
{'loss': 0.1925, 'grad_norm': 0.8644058108329773, 'learning_rate': 4.553824362606233e-05, 'epoch': 5.75}
{'loss': 0.1843, 'grad_norm': 0.6672417521476746, 'learning_rate': 4.48300283286119e-05, 'epoch': 5.82}
{'loss': 0.2099, 'grad_norm': 0.6725532412528992, 'learning_rate': 4.412181303116147e-05, 'epoch': 5.89}
{'loss': 0.1809, 'grad_norm': 0.6195104122161865, 'learning_rate': 4.341359773371105e-05, 'epoch': 5.95}
{'eval_loss': 0.12925338745117188, 'eval_runtime': 47.4576, 'eval_samples_per_second': 207.68, 'eval_steps_per_second': 25.96, 'epoch': 5.95}
{'loss': 0.1814, 'grad_norm': 0.6144781112670898, 'learning_rate': 4.270538243626063e-05, 'epoch': 6.02}
{'loss': 0.1666, 'grad_norm': 0.6910243034362793, 'learning_rate': 4.19971671388102e-05, 'epoch': 6.08}
{'loss': 0.1737, 'grad_norm': 0.6657938957214355, 'learning_rate': 4.1288951841359775e-05, 'epoch': 6.15}
{'loss': 0.1737, 'grad_norm': 0.8775849938392639, 'learning_rate': 4.058073654390935e-05, 'epoch': 6.22}
{'loss': 0.1777, 'grad_norm': 0.6734902262687683, 'learning_rate': 3.9872521246458926e-05, 'epoch': 6.28}
{'loss': 0.176, 'grad_norm': 0.6651109457015991, 'learning_rate': 3.91643059490085e-05, 'epoch': 6.35}
{'loss': 0.1747, 'grad_norm': 1.1433513164520264, 'learning_rate': 3.845609065155808e-05, 'epoch': 6.42}
{'loss': 0.1848, 'grad_norm': 0.6503381133079529, 'learning_rate': 3.774787535410765e-05, 'epoch': 6.48}
{'loss': 0.1568, 'grad_norm': 0.8790367841720581, 'learning_rate': 3.703966005665723e-05, 'epoch': 6.55}
{'loss': 0.1723, 'grad_norm': 0.7641950249671936, 'learning_rate': 3.63314447592068e-05, 'epoch': 6.61}
{'eval_loss': 0.1293131709098816, 'eval_runtime': 47.5763, 'eval_samples_per_second': 207.162, 'eval_steps_per_second': 25.895, 'epoch': 6.61}
{'loss': 0.1863, 'grad_norm': 0.6605756878852844, 'learning_rate': 3.562322946175637e-05, 'epoch': 6.68}
{'loss': 0.203, 'grad_norm': 0.9808638095855713, 'learning_rate': 3.4915014164305945e-05, 'epoch': 6.75}
{'loss': 0.1735, 'grad_norm': 0.6178171038627625, 'learning_rate': 3.4206798866855524e-05, 'epoch': 6.81}
{'loss': 0.1775, 'grad_norm': 0.649745523929596, 'learning_rate': 3.3498583569405103e-05, 'epoch': 6.88}
{'loss': 0.1739, 'grad_norm': 0.7578715682029724, 'learning_rate': 3.2790368271954676e-05, 'epoch': 6.95}
{'loss': 0.1854, 'grad_norm': 0.7297946214675903, 'learning_rate': 3.208215297450425e-05, 'epoch': 7.01}
{'loss': 0.1592, 'grad_norm': 0.7048734426498413, 'learning_rate': 3.137393767705383e-05, 'epoch': 7.08}
{'loss': 0.1676, 'grad_norm': 0.7271681427955627, 'learning_rate': 3.06657223796034e-05, 'epoch': 7.14}
{'loss': 0.1816, 'grad_norm': 0.9423546195030212, 'learning_rate': 2.9957507082152975e-05, 'epoch': 7.21}
{'loss': 0.1646, 'grad_norm': 0.3903930187225342, 'learning_rate': 2.9249291784702547e-05, 'epoch': 7.28}
{'eval_loss': 0.1223222091794014, 'eval_runtime': 47.5568, 'eval_samples_per_second': 207.247, 'eval_steps_per_second': 25.906, 'epoch': 7.28}
{'loss': 0.1599, 'grad_norm': 0.9352461099624634, 'learning_rate': 2.8541076487252126e-05, 'epoch': 7.34}
{'loss': 0.17, 'grad_norm': 0.8650583028793335, 'learning_rate': 2.7832861189801702e-05, 'epoch': 7.41}
{'loss': 0.1694, 'grad_norm': 0.7460044026374817, 'learning_rate': 2.7124645892351274e-05, 'epoch': 7.47}
{'loss': 0.1716, 'grad_norm': 0.7319803237915039, 'learning_rate': 2.641643059490085e-05, 'epoch': 7.54}
{'loss': 0.1538, 'grad_norm': 0.9971581101417542, 'learning_rate': 2.570821529745043e-05, 'epoch': 7.61}
{'loss': 0.1665, 'grad_norm': 0.6033250093460083, 'learning_rate': 2.5e-05, 'epoch': 7.67}
{'loss': 0.1608, 'grad_norm': 0.6399595141410828, 'learning_rate': 2.4291784702549577e-05, 'epoch': 7.74}
{'loss': 0.1559, 'grad_norm': 0.6471536159515381, 'learning_rate': 2.3583569405099153e-05, 'epoch': 7.8}
{'loss': 0.1658, 'grad_norm': 0.7357584238052368, 'learning_rate': 2.2875354107648728e-05, 'epoch': 7.87}
{'loss': 0.1573, 'grad_norm': 0.48644202947616577, 'learning_rate': 2.21671388101983e-05, 'epoch': 7.94}
{'eval_loss': 0.11959921568632126, 'eval_runtime': 47.5867, 'eval_samples_per_second': 207.117, 'eval_steps_per_second': 25.89, 'epoch': 7.94}
{'loss': 0.155, 'grad_norm': 0.6586951017379761, 'learning_rate': 2.1458923512747876e-05, 'epoch': 8.0}
{'loss': 0.17, 'grad_norm': 1.0512845516204834, 'learning_rate': 2.0750708215297452e-05, 'epoch': 8.07}
{'loss': 0.1526, 'grad_norm': 0.6353455185890198, 'learning_rate': 2.0042492917847027e-05, 'epoch': 8.14}
{'loss': 0.1529, 'grad_norm': 0.4623546898365021, 'learning_rate': 1.93342776203966e-05, 'epoch': 8.2}
{'loss': 0.156, 'grad_norm': 0.6892125010490417, 'learning_rate': 1.862606232294618e-05, 'epoch': 8.27}
{'loss': 0.1582, 'grad_norm': 0.8361925482749939, 'learning_rate': 1.791784702549575e-05, 'epoch': 8.33}
{'loss': 0.1477, 'grad_norm': 0.5819867253303528, 'learning_rate': 1.7209631728045327e-05, 'epoch': 8.4}
{'loss': 0.1706, 'grad_norm': 24.972620010375977, 'learning_rate': 1.6501416430594902e-05, 'epoch': 8.47}
{'loss': 0.1472, 'grad_norm': 0.39744338393211365, 'learning_rate': 1.5793201133144478e-05, 'epoch': 8.53}
{'loss': 0.1587, 'grad_norm': 0.905105471611023, 'learning_rate': 1.5084985835694052e-05, 'epoch': 8.6}
{'eval_loss': 0.1205003634095192, 'eval_runtime': 47.4333, 'eval_samples_per_second': 207.786, 'eval_steps_per_second': 25.973, 'epoch': 8.6}
{'loss': 0.1599, 'grad_norm': 0.4893130958080292, 'learning_rate': 1.4376770538243628e-05, 'epoch': 8.66}
{'loss': 0.1545, 'grad_norm': 0.4177435636520386, 'learning_rate': 1.3668555240793202e-05, 'epoch': 8.73}
{'loss': 0.1476, 'grad_norm': 0.4339315891265869, 'learning_rate': 1.2960339943342777e-05, 'epoch': 8.8}
{'loss': 0.1665, 'grad_norm': 0.9070913195610046, 'learning_rate': 1.2252124645892351e-05, 'epoch': 8.86}
{'loss': 0.155, 'grad_norm': 1.3790314197540283, 'learning_rate': 1.1543909348441927e-05, 'epoch': 8.93}
{'loss': 0.1633, 'grad_norm': 0.486191987991333, 'learning_rate': 1.0835694050991501e-05, 'epoch': 9.0}
{'loss': 0.1377, 'grad_norm': 0.709079921245575, 'learning_rate': 1.0127478753541077e-05, 'epoch': 9.06}
{'loss': 0.159, 'grad_norm': 0.3338207006454468, 'learning_rate': 9.419263456090652e-06, 'epoch': 9.13}
{'loss': 0.1494, 'grad_norm': 0.6013497710227966, 'learning_rate': 8.711048158640226e-06, 'epoch': 9.19}
{'loss': 0.1439, 'grad_norm': 0.5884362459182739, 'learning_rate': 8.002832861189802e-06, 'epoch': 9.26}
{'eval_loss': 0.11804895102977753, 'eval_runtime': 47.4784, 'eval_samples_per_second': 207.589, 'eval_steps_per_second': 25.949, 'epoch': 9.26}
{'loss': 0.1589, 'grad_norm': 1.1970248222351074, 'learning_rate': 7.294617563739377e-06, 'epoch': 9.33}
{'loss': 0.153, 'grad_norm': 0.7572697997093201, 'learning_rate': 6.5864022662889514e-06, 'epoch': 9.39}
{'loss': 0.144, 'grad_norm': 0.6750587821006775, 'learning_rate': 5.878186968838527e-06, 'epoch': 9.46}
{'loss': 0.1566, 'grad_norm': 0.5687661170959473, 'learning_rate': 5.169971671388102e-06, 'epoch': 9.52}
{'loss': 0.1501, 'grad_norm': 0.4746261537075043, 'learning_rate': 4.461756373937677e-06, 'epoch': 9.59}
{'loss': 0.1501, 'grad_norm': 0.8044806718826294, 'learning_rate': 3.753541076487253e-06, 'epoch': 9.66}
{'loss': 0.1461, 'grad_norm': 0.7612106800079346, 'learning_rate': 3.045325779036827e-06, 'epoch': 9.72}
{'loss': 0.1533, 'grad_norm': 0.5625903606414795, 'learning_rate': 2.3371104815864024e-06, 'epoch': 9.79}
{'loss': 0.1434, 'grad_norm': 0.7763766050338745, 'learning_rate': 1.6288951841359775e-06, 'epoch': 9.86}
{'loss': 0.1568, 'grad_norm': 0.4898182153701782, 'learning_rate': 9.206798866855524e-07, 'epoch': 9.92}
{'eval_loss': 0.11857079714536667, 'eval_runtime': 47.3724, 'eval_samples_per_second': 208.054, 'eval_steps_per_second': 26.007, 'epoch': 9.92}
{'loss': 0.1604, 'grad_norm': 0.6405250430107117, 'learning_rate': 2.1246458923512751e-07, 'epoch': 9.99}
{'train_runtime': 3999.9615, 'train_samples_per_second': 60.433, 'train_steps_per_second': 1.89, 'train_loss': 0.6617969267898136, 'epoch': 10.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7560/7560 [1:06:39<00:00,  1.89it/s]

======================================================================
‚úì Training completed successfully!
======================================================================

Saving final model...

Cleaning up old checkpoints...
   Deleted: checkpoint-7500

======================================================================
üéâ TRAINING COMPLETE!
======================================================================
Model saved to: ./s2p_model_polish_phoneme_v1
Vocabulary size: 39
Training samples: 24,173
Validation samples: 9,856
Language: Polish (pl)
======================================================================